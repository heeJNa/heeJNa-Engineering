# Superpowers 상세 사용 설명서

> 검증된 개발 방법론을 AI에 주입하여, AI가 "올바른 방법"으로 코드를 작성하게 만든다.

---

## 개요

Superpowers는 Jesse Vincent(obra)가 만든 Claude Code 플러그인으로, **TDD(테스트 주도 개발), 체계적 디버깅, 검증 루프** 등 검증된 소프트웨어 개발 방법론을 AI의 작업 습관에 주입한다.

### 비유

> 요리사(AI)에게 레시피북(Superpowers)을 주는 것과 같다. 레시피북 없이도 요리(코딩)는 할 수 있지만, 레시피북이 있으면 "맛을 보면서 간을 맞추고(TDD)", "불이 타면 원인부터 파악하고(Systematic Debugging)", "손님에게 내놓기 전에 검수하는(Verification Loop)" 습관이 자동으로 적용된다.

---

## 설치

```bash
# Claude Code 내에서 실행
/install obra/superpowers
```

설치 후 Claude Code가 코드를 작성할 때 자동으로 방법론이 활성화된다.

---

## 제공 스킬

### 1. TDD (Test-Driven Development) — 테스트 주도 개발

**핵심:** 코드를 먼저 작성하는 것이 아니라, **테스트를 먼저 작성**하고 테스트를 통과하는 코드를 작성한다.

#### 왜 필요한가?

AI가 코드를 생성하면 "동작하는 것 같은" 코드가 나온다. 하지만 엣지 케이스나 예외 상황에서 실패할 수 있다. 테스트를 먼저 작성하면:

- AI가 **정확히 무엇을 구현해야 하는지** 명확해진다
- 구현 후 **즉시 맞는지 틀린지** 확인할 수 있다
- 나중에 코드를 수정해도 **기존 기능이 깨지지 않았는지** 확인할 수 있다

#### 워크플로우

```
[1단계] 인간이 테스트 시나리오를 자연어로 기술
  "사용자가 만료된 토큰으로 API를 호출하면 401을 반환해야 한다"

[2단계] AI가 테스트 코드를 작성
  test_expired_token_returns_401()

[3단계] AI가 테스트를 통과하는 구현 코드 작성

[4단계] 인간이 테스트 결과 확인
```

#### 사용 방법

Superpowers 설치 후 자연스럽게 적용된다:

```
"이 함수에 대한 테스트를 먼저 작성하고, 그다음 구현해줘"
```

또는 AI가 자동으로 TDD를 적용한다:
```
Claude: "먼저 테스트 케이스를 작성하겠습니다."
→ 테스트 코드 작성
→ 테스트 실행 (실패 확인)
→ 구현 코드 작성
→ 테스트 실행 (통과 확인)
```

#### TDD 적용 기준

| 작업 유형 | TDD 적용 | 이유 |
|-----------|----------|------|
| 새 비즈니스 로직 | **필수** | 도메인 규칙의 정확성 보장 |
| 버그 수정 | **강력 권장** | 실패 테스트 먼저 작성 → 수정 → 통과 |
| API 엔드포인트 | **권장** | 계약(contract) 검증 |
| 유틸리티 함수 | **필수** | 입출력이 명확하므로 효과 극대화 |
| UI 컴포넌트 | 선택적 | 시각적 검증이 더 효과적인 경우 있음 |
| 리팩토링 | **필수** | 기존 동작 보존 확인 |

#### 실전 예시

```
사용자: "할인 계산 함수를 만들어줘. 10% 할인, VIP는 20%, 최소 금액 1000원"

[Superpowers TDD 적용]

Claude: "먼저 테스트를 작성하겠습니다."

테스트 코드:
  - test_일반_고객_10퍼센트_할인()
  - test_VIP_고객_20퍼센트_할인()
  - test_최소_금액_1000원_미만_할인_불가()
  - test_음수_금액_입력_에러()
  - test_0원_입력_처리()

→ 테스트 실행: 5개 모두 FAIL (아직 구현 안 했으므로 정상)
→ 구현 코드 작성
→ 테스트 실행: 5개 모두 PASS
```

---

### 2. Systematic Debugging — 체계적 디버깅

**핵심:** 버그를 보자마자 코드를 고치는 것이 아니라, **근본 원인을 먼저 체계적으로 파악**한 후 수정한다.

#### 왜 필요한가?

AI에게 "이 버그 고쳐줘"라고 하면, AI는 **증상만 가리는 패치**를 만들 수 있다. 진통제를 먹어서 통증은 사라지지만, 병 자체는 낫지 않는 것과 같다. 체계적 디버깅은 근본 원인을 찾아 치료한다.

#### 7단계 프로세스

```
1. 증상 확인
   정확히 무엇이 잘못되었는가?
   "API가 500 에러를 반환한다"

2. 재현
   어떤 조건에서 발생하는가?
   "특정 사용자의 프로필 조회 시에만 발생"

3. 가설 수립
   가능한 원인 3가지 이상 나열
   - A: DB에 해당 사용자 데이터 없음
   - B: NULL 값 처리 누락
   - C: 권한 설정 오류

4. 가설 검증
   각 가설을 하나씩 증거로 확인
   - A: DB 직접 조회 → 데이터 있음 (탈락)
   - B: 로그 확인 → NoneType 에러 발견! (유력)
   - C: 검증 불필요 (B 확정)

5. 근본 원인 확정
   NULL 체크 누락 확정

6. 수정
   증상 패치가 아닌 근본 원인 해결

7. 회귀 테스트
   같은 버그가 재발하지 않도록 테스트 추가
```

#### 사용 방법

Superpowers 설치 후, 버그 수정 요청 시 자동 적용된다:

```
"API 500 에러가 발생하고 있어. 원인을 파악하고 수정해줘"

Claude: [Systematic Debugging 적용]
"먼저 증상을 확인하겠습니다..."
→ 로그 분석
→ 가설 수립
→ 가설 검증
→ 근본 원인 확정
→ 수정 + 회귀 테스트
```

#### 잘못된 디버깅 vs 올바른 디버깅

**잘못된 방식 (증상 패치):**
```
문제: user.profile.name에서 NoneType 에러
수정: if user and user.profile and user.profile.name: ...
결과: 에러는 안 나지만, 왜 user가 None인지는 모름
```

**올바른 방식 (근본 원인 해결):**
```
문제: user.profile.name에서 NoneType 에러
분석: 삭제된 사용자의 캐시가 만료되지 않아 참조 발생
수정: 사용자 삭제 시 캐시 무효화 로직 추가
테스트: 삭제된 사용자 접근 시 적절한 에러 반환 확인
```

---

### 3. Verification Loop — 검증 루프

**핵심:** AI가 코드를 작성한 후, **자동으로 검증 단계를 실행**하여 품질을 확인한다.

#### 워크플로우

```
코드 작성
    ↓
[자동 검증 단계]
  1. lint 실행 (코드 스타일 확인)
  2. typecheck 실행 (타입 안전성 확인)
  3. test 실행 (기능 정확성 확인)
    ↓
통과?  → YES → 완료
       → NO  → 수정 후 재검증 (반복)
```

#### Quality Gate와의 관계

| 구분 | Verification Loop (Superpowers) | Quality Gate (Hook) |
|------|-------------------------------|---------------------|
| 실행 시점 | 코드 작성 직후 (AI가 자발적) | 커밋/작업 종료 시 (시스템이 강제) |
| 실행 주체 | AI 에이전트 | Shell 스크립트 |
| 유연성 | AI가 판단하여 적용 | 항상 실행 (결정적) |
| 성격 | 자율적 검증 | 강제적 검증 |

**둘 다 사용**하는 것이 이상적이다. Verification Loop은 "AI가 스스로 확인", Quality Gate는 "시스템이 최종 검수".

---

### 4. Incremental Development — 점진적 개발

**핵심:** 큰 기능을 **한 번에 만들지 않고, 작은 단위로 나눠서** 하나씩 완성한다.

#### 왜 필요한가?

AI가 한 번에 200줄짜리 코드를 생성하면 디버깅이 어렵다. 20줄씩 10번에 나눠서 만들면, 각 단계에서 문제를 즉시 발견하고 수정할 수 있다.

#### 패턴

```
1. 최소 동작 버전 (Skeleton)
   - 빈 함수/컴포넌트 구조만 생성
   - 컴파일/빌드 통과 확인

2. 핵심 기능 (Core)
   - 가장 중요한 기능 하나만 구현
   - 테스트로 검증

3. 추가 기능 (Enhancement)
   - 하나씩 기능 추가
   - 각 추가마다 테스트

4. 엣지 케이스 (Edge Cases)
   - 예외 처리, 에러 핸들링
   - 최종 검증
```

#### 실전 예시

```
"검색 기능이 있는 테이블 컴포넌트를 만들어줘"

[Incremental Development 적용]

Step 1: 기본 테이블 (데이터 표시만)
  → 테스트 → 통과

Step 2: 정렬 기능 추가
  → 테스트 → 통과

Step 3: 검색 필터 추가
  → 테스트 → 통과

Step 4: 페이지네이션 추가
  → 테스트 → 통과

Step 5: 에러 처리 + 로딩 상태
  → 최종 테스트 → 통과
```

---

## 주의사항

### SDD(Spec-Driven Development)와의 충돌

Superpowers에 포함된 SDD 스킬은 **Sisyphus의 Todo 기반 워크플로우와 충돌**한다.

```
사용하는 것:  TDD, Systematic Debugging, Verification Loop, Incremental Development
사용하지 않는 것:  SDD (Spec-Driven Development)
```

SDD는 스펙 파일을 먼저 작성하는 방식인데, Sisyphus가 이미 Todo 목록으로 작업을 관리하므로 충돌이 발생한다.

### Superpowers만 사용하면 부족한 이유

Superpowers는 **방법론(어떻게 일할 것인가)**을 제공하지만, **오케스트레이션(여러 에이전트가 어떻게 협업할 것인가)**은 제공하지 않는다. 따라서 **OMC와 함께 사용**해야 완전한 프레임워크가 된다.

| 제공하는 것 | 제공하지 않는 것 |
|------------|-----------------|
| TDD 습관 | 멀티 에이전트 조율 |
| 체계적 디버깅 프로세스 | 병렬 실행 |
| 검증 루프 | 계획 수립 |
| 점진적 개발 패턴 | 비판적 리뷰 |

---

## OMC와의 시너지

```
[Superpowers]                    [OMC]
  TDD로 테스트 먼저 작성    +   Sisyphus로 Todo 관리
  Systematic Debugging      +   Oracle로 근본 원인 분석
  Verification Loop         +   Quality Gate로 자동 검증
  Incremental Development   +   Ultrawork로 병렬 실행
```

**Superpowers는 "개발자 한 명의 작업 습관"**, **OMC는 "AI 팀의 협업 방식"**을 정의한다.

---

## 참고

- [Superpowers GitHub 저장소](https://github.com/obra/superpowers)
- [방법론](methodology.md) — TDD/디버깅 적용 시점 판단
- [레퍼런스](references.md) — 원저자 obra의 설계 철학
